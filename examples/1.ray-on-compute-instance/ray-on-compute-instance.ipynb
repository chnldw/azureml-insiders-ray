{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ray on compute instance\n",
        "\n",
        "In this notebook, we would learn how to start a local Ray cluster and interactively execute Ray script using Azure ML Compute Instance.\n",
        "\n",
        "The user should have completed the Azure Machine Learning Tutorial: [Get started creating your first ML experiment with the Python SDK](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-1st-experiment-sdk-setup). \n",
        "\n",
        "You will need to make sure that you have a valid subscription ID, a resource group, and an Azure Machine Learning workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required packages\n",
        "\n",
        "More info about installing Ray could be found [here](https://docs.ray.io/en/latest/ray-overview/installation.html)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --no-cache-dir \\\n",
        "  ../../private_wheel/azure_ai_ml-1.6.0a20230421002-py3-none-any.whl \\\n",
        "  'ray[default, air, tune]==2.4.0' \\\n",
        "  gpustat==1.0.0 \\\n",
        "  torch \\\n",
        "  torchvision"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682980524902
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start a local Ray cluster\r\n",
        "\r\n",
        "By running `ray.init`, we would start a local interactive Ray cluster within compute instance. To access the Ray dashboard from browser, we could use link with following pattern:\r\n",
        "`https://{compute_instance_name}-{dashboard-port}.{region}.instances.azureml.ms`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "import configparser\n",
        "\n",
        "dashboard_port = 8265\n",
        "\n",
        "ray_instance = ray.init(\n",
        "    include_dashboard= True,\n",
        "    dashboard_port=dashboard_port,\n",
        "    ignore_reinit_error=True\n",
        ")\n",
        "\n",
        "\n",
        "# update Ray dashboard link\n",
        "try:\n",
        "    parser = configparser.ConfigParser()\n",
        "    with open(\"/mnt/azmnt/.nbvm\") as stream:\n",
        "        parser.read_string(\"[config]\\n\" + stream.read())\n",
        "\n",
        "    config = parser['config']\n",
        "    ci_name = config['instance']\n",
        "    domainsuffix = config['domainsuffix']\n",
        "\n",
        "    dashboard_url = f'{ci_name}-{dashboard_port}.{domainsuffix}'\n",
        "except:\n",
        "    dashboard_url = ray_instance.dashboard_url\n",
        "\n",
        "ray_instance.dashboard_url = dashboard_url\n",
        "ray_instance"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682980528072
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Started with Model Training in Ray\n",
        "\n",
        "After `ray` installed, we can start a local Ray cluster and train a model using Ray.\n",
        "\n",
        "Let's use this `PyTorch` example from Ray [website](https://docs.ray.io/en/latest/train/getting-started.html)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First, set up your dataset and model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "num_samples = 20\n",
        "input_size = 10\n",
        "layer_size = 15\n",
        "output_size = 5\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, layer_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(layer_size, output_size)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.layer2(self.relu(self.layer1(input)))\n",
        "\n",
        "# In this example we use a randomly generated dataset.\n",
        "input = torch.randn(num_samples, input_size)\n",
        "labels = torch.randn(num_samples, output_size)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682980528168
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next, define your multi-worker `PyTorch` training function."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import train\n",
        "from torch import optim\n",
        "\n",
        "def train_func_distributed():\n",
        "    num_epochs = 3\n",
        "    model = NeuralNetwork()\n",
        "    model = train.torch.prepare_model(model)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        output = model(input)\n",
        "        loss = loss_fn(output, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"epoch: {epoch}, loss: {loss.item()}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682980532094
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Then, train the model using `TorchTrainer`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from ray.train.torch import TorchTrainer\n",
        "from ray.air.config import ScalingConfig\n",
        "\n",
        "num_workers = 3\n",
        "\n",
        "trainer = TorchTrainer(\n",
        "    train_func_distributed,\n",
        "    scaling_config=ScalingConfig(num_workers=num_workers)\n",
        ")\n",
        "\n",
        "results = trainer.fit()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682980541192
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shutdown local Ray cluster"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ray.shutdown()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682980569970
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}