{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Ray on interactive compute cluster\n",
    "\n",
    "In [ray-on-compute-instance notebook](../1.ray-on-compute-instance/ray-on-compute-instance.ipynb), we learned how to start a local Ray cluster and interactively execute Ray script on compute instance.\n",
    "\n",
    "In [ray-on-compute-cluster](../2.ray-on-compute-cluster/ray-on-compute-cluster.ipynb), we learned how to submit a distributed training job with Ray cluster enabled onto multi-nodes Azure ML compute clusters.\n",
    "\n",
    "In this notebook, we would learn how to combine this 2 scenarios to build a multi-nodes heterogeneous Ray cluster, and interactively execute Ray application.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prerequisites\n",
    "To build an interactive multi-nodes heterogeneous Ray cluster, we need one compute instance as head node and one or more cpu/gpu compute clusters as worker nodes.\n",
    "\n",
    "The compute instance and compute cluster are required to be placed in one virtual network and subnet.\n",
    "\n",
    "Please follow [this document](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-secure-training-vnet?view=azureml-api-2&tabs=cli%2Crequired) to setup 1 cpu compute instance and 2 nodes gpu compute cluster."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Install required packages\n",
    "\n",
    "More info about installing Ray could be found [here](https://docs.ray.io/en/latest/ray-overview/installation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682983694785
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install \\\n",
    "  \"azure-ai-ml>=1.6.0\" \\\n",
    "  \"ray[default, air, tune]==2.4.0\" \\\n",
    "  gpustat==1.0.0 \\\n",
    "  torch \\\n",
    "  torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Start a Ray cluster on compute instance\n",
    "\n",
    "We would use the current compute instance as head node of the Ray cluster we are trying to build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1682983784336
    }
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import configparser\n",
    "\n",
    "dashboard_port = 8265\n",
    "\n",
    "ray_instance = ray.init(\n",
    "    include_dashboard= True,\n",
    "    dashboard_port=dashboard_port,\n",
    "    ignore_reinit_error=True\n",
    ")\n",
    "\n",
    "\n",
    "# update Ray dashboard link\n",
    "try:\n",
    "    parser = configparser.ConfigParser()\n",
    "    with open(\"/mnt/azmnt/.nbvm\") as stream:\n",
    "        parser.read_string(\"[config]\\n\" + stream.read())\n",
    "\n",
    "    config = parser['config']\n",
    "    ci_name = config['instance']\n",
    "    domainsuffix = config['domainsuffix']\n",
    "\n",
    "    dashboard_url = f'{ci_name}-{dashboard_port}.{domainsuffix}'\n",
    "except:\n",
    "    dashboard_url = ray_instance.dashboard_url\n",
    "\n",
    "ray_instance.dashboard_url = dashboard_url\n",
    "ray_instance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Attach worker nodes using compute cluster\n",
    "\n",
    "After head node started, we can submit a worker nodes only job by passing the head node address."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682983758208
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, command\n",
    "from azure.ai.ml.entities import Environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Connect to workspace using DefaultAzureCredential\n",
    "\n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682983761215
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "    workspace = ml_client.workspace_name\n",
    "    subscription_id = ml_client.workspaces.get(workspace).id.split(\"/\")[2]\n",
    "    resource_group = ml_client.workspaces.get(workspace).resource_group\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Build environment\n",
    "\n",
    "We would use Azure ML image and a conda yaml file to build an environment. More info about how to build environment could be found [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2?view=azureml-api-2&tabs=python).\n",
    "\n",
    "As Ray requires exact version match of both `python` and `ray`, let's generate a `conda.yml` file matches current kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682983765206
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from platform import python_version\n",
    "\n",
    "# Get and set python and ray version\n",
    "python_version = python_version()\n",
    "ray_version = '2.4.0'\n",
    "\n",
    "conda = yaml.load(f\"\"\"\n",
    "    name: ray-environment\n",
    "    dependencies:\n",
    "    - python={python_version}\n",
    "    - pip:\n",
    "        - ray[default, tune]=={ray_version}\n",
    "        - torch\n",
    "        - torchvision\n",
    "\"\"\", Loader=yaml.CLoader)\n",
    "\n",
    "# Write to conda.yml file\n",
    "with open('conda.yml', 'w') as conda_file:\n",
    "    yaml.dump(conda, conda_file, default_flow_style=False)\n",
    "\n",
    "\n",
    "# Build environment using AzureML image and conda.yml we built\n",
    "environment=Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.3-cudnn8-ubuntu20.04\",\n",
    "    conda_file=\"conda.yml\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Configure and Run Command\n",
    "In this section we will be configuring and running a `Command` job.\n",
    "\n",
    "The `command` allows user to configure the following key aspects.\n",
    "- `command` - This is the command that needs to be run. In this example, we would execute `sleep infinity` which would block the job to complete.\n",
    "- `environment` - This is the environment needed for the command to run. In this example, we would use the environment we just build.\n",
    "- `compute` - The compute on which the command will run. In this example, we specify the compute we created in the same vnet of current compute instance.\n",
    "- `instance_count` - The number of nodes to use for the job. In this example, we would scale `2` nodes.\n",
    "- `distribution` - Distribution configuration for distributed training scenarios. In this example, we would set it to `ray`. Azure ML job engine would setup Ray cluster automatically.\n",
    "  - `port` - \\[Optional\\] The port of the head ray process. Default is `6379`\n",
    "  - `address` - \\[Optional\\] The address of Ray head node.\n",
    "  - `worker_node_additional_args` - \\[Optional\\] Additional arguments passed to ray start in worker node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682983766319
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "job = command(\n",
    "    experiment_name=\"mnist_pytorch\",\n",
    "    command=\"sleep infinity\",\n",
    "    environment=environment,\n",
    "    compute=\"gpu-cluster\",\n",
    "    instance_count=2,  # In this, only 2 node cluster was created.\n",
    "    distribution={\n",
    "        \"type\": \"ray\",\n",
    "        \"address\": ray_instance.address_info[\"address\"], # [Optional] The address of ray head node\n",
    "        # \"worker_node_additional_args\": \"--verbose\", # [Optional] Additional arguments passed to ray start in head node.\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Submit the job\n",
    "\n",
    "By submitting the command job, Azure ML would scale up the compute cluster and connect to the head node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682983773230
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "active_job = ml_client.jobs.create_or_update(job)\n",
    "\n",
    "active_job"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prepare the training script\n",
    "We would continue to use the same PyTorch example from Ray:\n",
    "[https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/mnist_pytorch.py](https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/mnist_pytorch.py)\n",
    "\n",
    "Script is downloaded into [src/mnist_pytorch.py](./src/mnist_pytorch.py)\n",
    "\n",
    "We would run the application _interactively_ and see the output in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%run src/mnist_pytorch.py --cuda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Show Ray cluster resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682654040765
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Shutdown the head and worker node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682654040962
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# shutdown head node\n",
    "ray.shutdown()\n",
    "\n",
    "# cancel worker job would automaticlaly shutdown worker node\n",
    "poller = ml_client.jobs.begin_cancel(name=active_job.name)\n",
    "\n",
    "# wait until job cancelled\n",
    "poller.wait()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
