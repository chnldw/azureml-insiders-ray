{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Ray and MLflow\n",
    "\n",
    "[MLflow](https://www.mlflow.org/) is an open-source framework that's designed to manage the complete machine learning lifecycle. Its ability to train and serve models on different platforms allows you to use a consistent set of tools regardless of where your experiments are running: locally on your computer, on a remote compute target, on a virtual machine, or on an Azure Machine Learning compute instance.\n",
    "\n",
    "Azure Machine Learning workspaces are **MLflow-compatible**, which means you can use Azure Machine Learning workspaces in the same way that you'd use an MLflow server. See [MLflow and Azure Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow?view=azureml-api-2&viewFallbackFrom=azureml-api-1) for all supported MLflow and Azure Machine Learning functionality including MLflow Project support (preview) and model deployment.\n",
    "\n",
    "\n",
    "In [ray-on-compute-cluster](../2.ray-on-compute-cluster/ray-on-compute-cluster.ipynb), we learned how to submit a distributed training job with Ray cluster enabled onto multi-nodes Azure ML compute clusters.\n",
    "\n",
    "In this notebook, we would show an example of Ray Tune, MLflow and Azure ML integration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --no-cache-dir \\\n",
    "  ../../private_wheel/azure_ai_ml-1.6.0a20230421002-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682656503212
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, command\n",
    "from azure.ai.ml.entities import Environment, BuildContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Connect to workspace using DefaultAzureCredential\n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it does not work for you: [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682656505191
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "    workspace = ml_client.workspace_name\n",
    "    subscription_id = ml_client.workspaces.get(workspace).id.split(\"/\")[2]\n",
    "    resource_group = ml_client.workspaces.get(workspace).resource_group\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Build training environment\n",
    "\n",
    "We would use Azure ML image and a conda yaml file to build an environment. More info about how to build environment could be found [here](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-environments-v2?view=azureml-api-2&tabs=python).\n",
    "\n",
    "**`azureml-mlflow`** package is required for MLflow and Azure ML integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682656505380
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from platform import python_version\n",
    "\n",
    "# Get and set python and ray version\n",
    "python_version = python_version()\n",
    "ray_version = '2.4.0'\n",
    "\n",
    "conda = yaml.load(f\"\"\"\n",
    "    name: ray-environment\n",
    "    dependencies:\n",
    "    - python={python_version}\n",
    "    - pip:\n",
    "        - ray[default, tune]=={ray_version}\n",
    "        - azureml-mlflow\n",
    "        - torch\n",
    "        - torchvision\n",
    "\"\"\", Loader=yaml.CLoader)\n",
    "\n",
    "# Write to conda.yml file\n",
    "with open('conda.yml', 'w') as conda_file:\n",
    "    yaml.dump(conda, conda_file, default_flow_style=False)\n",
    "\n",
    "\n",
    "# Build environment using AzureML image and conda.yml we built\n",
    "environment=Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file=\"conda.yml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Enable `MLflow` tracking\n",
    "\n",
    "Ray support multiple integration with `MLflow`. We would use `MLflowLoggerCallback` with Ray Tune here.\n",
    "\n",
    "Follow [Use MLflow with Tune](https://docs.ray.io/en/latest/tune/examples/tune-mlflow.html) document to modify the training script.\n",
    "\n",
    "In this example, we would add each trial as nested run of the Command job we are going to submit.\n",
    "\n",
    "Here's the modification we need to make to enable `MLflow` tracking.\n",
    "\n",
    "```python\n",
    "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
    "import mlflow\n",
    "from mlflow.utils.mlflow_tags import MLFLOW_PARENT_RUN_ID\n",
    "\n",
    "# get or start mlflow run.\n",
    "current_run = mlflow.active_run()\n",
    "if(current_run is None):\n",
    "    current_run = mlflow.start_run()\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    run_config=air.RunConfig(\n",
    "        # Enable MLflow by using MLflowLoggerCallback\n",
    "        callbacks=[MLflowLoggerCallback(\n",
    "            tags={\n",
    "                MLFLOW_PARENT_RUN_ID: current_run.info.run_id # each trial would be added as nested run.\n",
    "            })],\n",
    "        # ... other run config\n",
    "    ),\n",
    "    # .. other configs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Configure and Run Command\n",
    "\n",
    "In this section we will be configuring and running a distributed training `Command` job.\n",
    "\n",
    "The `command` allows user to configure the following key aspects.\n",
    "- `code` - This is the path where the code to run the command is located.\n",
    "- `command` - This is the command that needs to be run. In this example, we would execute `mnist_pytorch.py` we downloaded from [ray github repo](https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/mnist_pytorch.py).\n",
    "- `environment` - This is the environment needed for the command to run. In this example, we would use the environment we just build.\n",
    "- `compute` - The compute on which the command will run. In this example, compute is not specified which means it would use `serverless` compute.\n",
    "- `instance_type` - VMSize of the `serverless` compute. In this example, we would use `Standard_DS3_v2` cpu cluster.\n",
    "- `instance_count` - The number of nodes to use for the job. In this example, we would scale `2` nodes.\n",
    "- `shm_size` - Size of the docker container's shared memory block. \n",
    "- `distribution` - Distribution configuration for distributed training scenarios. In this example, we would set it to `ray`. Azure ML job engine would setup Ray cluster automatically.\n",
    "  - `port` - \\[Optional\\] The port of the head ray process. Default is `6379`\n",
    "  - `address` - \\[Optional\\] The address of Ray head node.\n",
    "  - `include_dashboard` - \\[Optional\\] Provide this argument to start the Ray dashboard GUI. Default is `True`\n",
    "  - `dashboard_port` - \\[Optional\\] The port to bind the dashboard server to. Default is `8265`\n",
    "  - `head_node_additional_args` - \\[Optional\\] Additional arguments passed to ray start in head node.\n",
    "  - `worker_node_additional_args` - \\[Optional\\] Additional arguments passed to ray start in worker node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682656505515
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "job = command(\n",
    "    experiment_name=\"mnist_pytorch_mlflow\",\n",
    "    code=\"./src\",  # local path where the code is stored\n",
    "    command=\"python mnist_pytorch_mlflow.py;\",\n",
    "    environment=Environment(\n",
    "        image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "        conda_file=\"conda.yml\"\n",
    "    ),\n",
    "    # compute=\"azureml:cpu-cluster\",\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=2,  # In this, only 2 node cluster was created.\n",
    "    shm_size=\"4g\", # ~30% of 14G node memory\n",
    "    distribution={\n",
    "        \"type\": \"ray\",\n",
    "        # \"port\": 6379, # [Optional] The port of the head ray process.\n",
    "        # \"include_dashboard\": True, # [Optional] The port of the head ray process.\n",
    "        # \"dashboard_port\": 8265, # [Optional] The port of the head ray process.\n",
    "        # \"head_node_additional_args\": \"--verbose\", # [Optional] Additional arguments passed to ray start in head node.\n",
    "        # \"worker_node_additional_args\": \"--verbose\", # [Optional] Additional arguments passed to ray start in head node.\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1682656511173
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "active_job = ml_client.jobs.create_or_update(job)\n",
    "\n",
    "active_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Use Azure ML Studio to explorer MLflow runs\n",
    "\n",
    "We can use [Azure ML Studio](https://ml.azure.com/) to explorer MLflow runs. All trials are displayed inside of the command job's **child jobs** tab.\n",
    "![Using Studio to explorer MFflow runs](./assets/mlflow_studio.png)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml-pt-tf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
