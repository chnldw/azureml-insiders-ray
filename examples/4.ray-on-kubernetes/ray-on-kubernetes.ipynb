{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608ec3a6-587c-4793-8a1f-e40b1d38b575",
   "metadata": {},
   "source": [
    "# Ray on kubernetes\n",
    "\n",
    "In [ray-on-compute-cluster](../2.ray-on-compute-cluster/ray-on-compute-cluster.ipynb), we learned how to submit a distributed training job with Ray cluster enabled onto multi-nodes Azure ML compute clusters.\n",
    "\n",
    "As Azure ML supports [Kubernetes as a compute target](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-attach-kubernetes-anywhere?view=azureml-api-2), we can easily submit a job with Ray cluster enabled onto an existing Azure Kubernetes Service (AKS) cluster or Azure Arc-enabled Kubernetes (Arc Kubernetes) cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08a88a-7518-48b7-bcf6-780dddeb57ff",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "With a simple cluster extension deployment on AKS or Arc Kubernetes cluster, Kubernetes cluster is seamlessly supported in Azure Machine Learning to run training or inference workload. It's easy to enable and use an existing Kubernetes cluster for Azure Machine Learning workload with the following simple steps:\n",
    "1. Prepare an Azure [Kubernetes Service cluster](https://learn.microsoft.com/en-us/azure/aks/learn/quick-kubernetes-deploy-cli) or [Arc Kubernetes cluster](https://learn.microsoft.com/en-us/azure/azure-arc/kubernetes/quickstart-connect-cluster).\n",
    "2. Deploy the [Azure Machine Learning extension](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-kubernetes-extension).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7a587-4a71-47ed-8700-3959f67185ab",
   "metadata": {},
   "source": [
    "## Attach Kubernetes cluster to your Azure ML workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a26bb-0cc5-4456-afd3-a66c768aad3f",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e566b905-359b-4ac9-868d-b7a4b7f7e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.ai.ml import MLClient, command\n",
    "from azure.ai.ml.entities import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fa6ad-2eb5-439c-b0a6-3621e9bb7f36",
   "metadata": {},
   "source": [
    "### Connect to workspace using DefaultAzureCredential\n",
    "\n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9285bf-8bd5-4538-8ee9-20d72eabb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential)\n",
    "    workspace = ml_client.workspace_name\n",
    "    subscription_id = ml_client.workspaces.get(workspace).id.split(\"/\")[2]\n",
    "    resource_group = ml_client.workspaces.get(workspace).resource_group\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    # Enter details of your AML workspace\n",
    "    subscription_id = \"<SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<RESOURCE_GROUP>\"\n",
    "    workspace = \"<AML_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97dbf4-1f4b-4575-9b5a-93436aa4f305",
   "metadata": {},
   "source": [
    "### Attach to workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecbac68-5c97-48a6-85bd-2ea2fc96e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_compute\n",
    "\n",
    "compute_name = \"aks-cluster\"\n",
    "\n",
    "try:\n",
    "    ml_client.compute.get(compute_name)\n",
    "    print(\"Found attached kubernetes cluster\")\n",
    "except Exception:\n",
    "    print(\"Attaching kubernetes culster...\")\n",
    "    # aks_cluster_id = \"/subscriptions/<SUBSCRIPTION_ID>/resourceGroups/<RESOURCE_GROUP>/providers/Microsoft.ContainerService/managedClusters/<CLUSTER_NAME>\"\n",
    "    aks_cluster_id = \"/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/daweil-ray/providers/Microsoft.ContainerService/managedClusters/daweil-ray\"\n",
    "\n",
    "    compute_params = [\n",
    "        {\"name\": compute_name},\n",
    "        {\"type\": \"kubernetes\"},\n",
    "        {\n",
    "            \"resource_id\": aks_cluster_id\n",
    "        },\n",
    "    ]\n",
    "    k8s_compute = load_compute(source=None, params_override=compute_params)\n",
    "    ml_client.compute.begin_create_or_update(k8s_compute).result()\n",
    "    print(\"Kubernetes culster is ready to use.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dbccaf-7276-4812-a6c2-f27dde911dd7",
   "metadata": {},
   "source": [
    "## Prepare the training script\n",
    "We would use the PyTorch example from Ray:\n",
    "[https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/mnist_pytorch.py](https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/mnist_pytorch.py)\n",
    "\n",
    "Script is downloaded into [src/mnist_pytorch.py](./src/mnist_pytorch.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c730f1c2-ba00-4658-b4c9-236eb40437b5",
   "metadata": {},
   "source": [
    "## Configure and Run Command\n",
    "\n",
    "In this section we will be configuring and running a distributed training `Command` job.\n",
    "\n",
    "The `command` allows user to configure the following key aspects.\n",
    "- `code` - This is the path where the code to run the command is located.\n",
    "- `command` - This is the command that needs to be run. In this example, we would execute `mnist_pytorch.py` we downloaded from [ray github repo](https://github.com/ray-project/ray/blob/master/python/ray/tune/examples/mnist_pytorch.py).\n",
    "- `environment` - This is the environment needed for the command to run. In this example, we would use `rayproject/ray-ml` image provided by `ray`.\n",
    "- `compute` - The compute on which the command will run. In this example, compute is set to kubernetes cluster we just attached.\n",
    "- `instance_count` - The number of nodes to use for the job. In this example, we would scale `2` nodes.\n",
    "- `distribution` - Distribution configuration for distributed training scenarios. In this example, we would set it to `ray`. Azure ML job engine would setup Ray cluster automatically.\n",
    "  - `port` - \\[Optional\\] The port of the head ray process. Default is `6379`\n",
    "  - `address` - \\[Optional\\] The address of Ray head node.\n",
    "  - `include_dashboard` - \\[Optional\\] Provide this argument to start the Ray dashboard GUI. Default is `True`\n",
    "  - `dashboard_port` - \\[Optional\\] The port to bind the dashboard server to. Default is `8265`\n",
    "  - `head_node_additional_args` - \\[Optional\\] Additional arguments passed to ray start in head node.\n",
    "  - `worker_node_additional_args` - \\[Optional\\] Additional arguments passed to ray start in worker node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341020f4-55fd-43ed-ac36-3386d4279668",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = command(\n",
    "    experiment_name=\"mnist_pytorch\",\n",
    "    code=\"./src\",  # local path where the code is stored\n",
    "    command=\"python mnist_pytorch.py;\",\n",
    "    environment=Environment(\n",
    "        image=\"rayproject/ray-ml:2.4.0-py38-cpu\"\n",
    "    ),\n",
    "    compute=\"aks-cluster\",\n",
    "    instance_count=2,  # In this, only 2 node cluster was created.\n",
    "    distribution={\n",
    "        \"type\": \"ray\",\n",
    "        # \"port\": 6379, # [Optional] The port of the head ray process.\n",
    "        # \"include_dashboard\": True, # [Optional] The port of the head ray process.\n",
    "        # \"dashboard_port\": 8265, # [Optional] The port of the head ray process.\n",
    "        # \"head_node_additional_args\": \"--verbose\", # [Optional] Additional arguments passed to ray start in head node.\n",
    "        # \"worker_node_additional_args\": \"--verbose\", # [Optional] Additional arguments passed to ray start in head node.\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c6346-911a-42ce-bef2-42b018d9a627",
   "metadata": {},
   "source": [
    "## Submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b637ba-2e34-404b-ac1e-667c4beb0850",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_job = ml_client.jobs.create_or_update(job)\n",
    "\n",
    "active_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66016bbd-6ef4-4ea1-a36e-3b90d74e13ef",
   "metadata": {},
   "source": [
    "## View Ray Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faffab9-1cb5-4a44-82db-0bfd24480669",
   "metadata": {},
   "source": [
    "### Retrieve Ray dashboard link through SDK\n",
    "After job started **running**, you could get link from `job.services`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2aa0b-c511-4603-b9a8-80729653e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display\n",
    "\n",
    "# wait until Ray dashboard is ready\n",
    "active_job = ml_client.jobs.get(active_job.name)\n",
    "\n",
    "dashboard_url = active_job.services['ray-dashboard'].endpoint.replace('<nodeIndex>', '0')\n",
    "display({'text/html': f'Ray Dashboard: <a href=\"{dashboard_url}\" rel=\"noreferrer\">{dashboard_url}</a>'}, raw=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
